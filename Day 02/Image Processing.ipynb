{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Processing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAZik0KUV18z",
        "colab_type": "text"
      },
      "source": [
        "# Image Processing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RhzU6RmXrps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All tasks and excercises are done in Tools.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zkEPQYth2xy",
        "colab_type": "text"
      },
      "source": [
        "There are four aspects of image processing: (In any Computer Vision pipeline)\n",
        "- **Aquisition**\n",
        "\n",
        "  Digitally encoded representation of the visual characteristics of a real world object. \n",
        "  \n",
        "  Low level digital representation of world scene\n",
        "   \n",
        "- **Processing**\n",
        "  - Noise removal\n",
        "  - Smoothimg\n",
        "  - Sharpening \n",
        "  - Contrast enhancement\n",
        "  \n",
        "  Altering the apperance/ enhancing the image.\n",
        "\n",
        "- **Compression**\n",
        "\n",
        "  Efficient storage of image to save space and efficient commucation by saving network bandwidth\n",
        "\n",
        "- **Display**\n",
        "\n",
        "  Rendering the image on reproduction media."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87Pys8LRXxNc",
        "colab_type": "text"
      },
      "source": [
        "### What is an Image?\n",
        "\n",
        "Pixel elements compose a digital image: `M x N pixels`\n",
        "\n",
        "Number of pixels, use to give the rectangular shape of the image, along with intensity values of the pixesls define an image.\n",
        "\n",
        "### **Greycale images**\n",
        "The pixels take 8 bit values ranging from $0$ to $(2^8 - 1)$. Depends on the bit-image.\n",
        "\n",
        "The value represents the grey level of the pixel.\n",
        "\n",
        "### **RGB Images**\n",
        "Has three colour channels: Red, Green and Blue.\n",
        "\n",
        "Has $8 * 3 = 24$ bit pixels representations.\n",
        "\n",
        "### **Binary** \n",
        "Combinations of 0's and 1's where 1 represents white and 0 represents black.\n",
        "\n",
        "### **Mutispectral Images**\n",
        "\n",
        "Captures the image data across specific wavelength ranges across the EM spectrum.\n",
        "\n",
        "Not just in visible light but in many bands such as IR, UV.\n",
        "\n",
        "### **Stereo Images**\n",
        "\n",
        "Have more information than from a normal image as the depth factor is present for depth perception. Just as in humans, the idea behind having two eyes.\n",
        "\n",
        "### **Multiview Images**\n",
        "\n",
        "Side, top, and angled views of an object for 3D reconstruction or any other application.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryC2c7hIUZXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task: To read and display images using OpenCV or any other Python libraries and view dimensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhY3oQAuVSj-",
        "colab_type": "text"
      },
      "source": [
        "### Spatial Domain Processing\n",
        "\n",
        "Spatial domain ante image plane, processing is done on the image plane where internsity values are manipulated as needed.\n",
        "\n",
        "- **Directly on the plane**\n",
        "\n",
        "  Go to (x, y)  and change the value.\n",
        "\n",
        "- **Point To Point**\n",
        "\n",
        "  Map the value at (x, y) to another value at (x, y) in another image/ matrix.\n",
        "\n",
        "- **Neighbourhood To Point (Local)**\n",
        "\n",
        "  The neighbourhood of the point (A window around the point), along with the point itself is used to generate a value at (x, y)\n",
        "\n",
        "- **Global To Point**\n",
        "\n",
        "  The whole image is used to generate a value at (x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQYuZqIBYRmZ",
        "colab_type": "text"
      },
      "source": [
        "### Intensity Transformations\n",
        "\n",
        "Mapping the intensity value $z$ at pixel $(x, y)$ to a new value $z'$ using function $g$:\n",
        "\n",
        "\\begin{equation}\n",
        "z' = g(z)\n",
        "\\end{equation}\n",
        "\n",
        "The function $g$ at the most basic level can be of three types:\n",
        "\n",
        "- **Linear**\n",
        "- **Logarithmic**\n",
        "- **Power Law / Gamma Transform**\n",
        "\n",
        "Graph Input Gray Level $r$ versus Output Gray Level $s$ trends:\n",
        "- **Identity function**: No change\n",
        "- **Negation**: Flips the image\n",
        "- **Log**: Produces more positive change than $n^{th}$ root \n",
        "- **Inverse Log**: Produces more negative change than $n^{th}$ power\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNdfJ_1yZ4z6",
        "colab_type": "text"
      },
      "source": [
        "### Linear Intensity Transformation\n",
        "\n",
        "To enhance white or black in an image by flipping using negative transformation. All blacks go to white and vice versa, to gain some clarity.\n",
        "\n",
        "*Example:* A mamogram\n",
        "\n",
        "### Log Transform\n",
        "\n",
        "\\begin{equation}\n",
        "s = c * log(1 + r)\n",
        "\\end{equation}\n",
        "\n",
        "*Example:* Fourier Spectrum\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itRoXku6a0zm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task: Perform intensity transformations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl60NJnnpDEz",
        "colab_type": "text"
      },
      "source": [
        "### Power Law Transform / Gamma\n",
        "\n",
        "\\begin{equation}\n",
        "s = c * r ^ {\\gamma}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\gamma = (-\\infty, \\infty)\n",
        "\\end{equation}\n",
        "\n",
        "A parameter representing how large you want to transform your image.\n",
        "\n",
        "\n",
        "When $\\gamma$ is large the range of output instensities is large. Larger range will help distinguish objects better.\n",
        "\n",
        "When $\\gamma$ is small the range of output instensities is small.\n",
        "\n",
        "$\\gamma$ greater than 1 gives high intensities, that is a more black image.\n",
        "\n",
        "$\\gamma$ lesser than 1 gives low intensities that is a more washed/ white image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_roE16wpEM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Excercise: Perform Power Law tansformation for different values of gamma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW4z795B2WXM",
        "colab_type": "text"
      },
      "source": [
        "### Histogram Grayscale\n",
        "\n",
        "Frequencies of intensity values are shown on histograms. Remember the bins?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcnfYBgx23WT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task: Represent an image using its intensity histogram "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzd6Km8s8yDE",
        "colab_type": "text"
      },
      "source": [
        "The histogram doesn't show the distribution of intensities, as in how the intensities are spread across the image. This is beacuse we are not corresponding it with the pixel location, we're throwing away that information :(\n",
        "\n",
        "Hence two different images can have the same statistics/ same histograms! Hence we cannot reconstruct images from their histograms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUcCSsst9jLC",
        "colab_type": "text"
      },
      "source": [
        "### Histogram Of Colour Intensities\n",
        "\n",
        "Plot three histograms for RGB and combine them to obtain more comprehensie statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4FUsOfW9tOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Excercise: Show colour histograms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75yYRKDALk5u",
        "colab_type": "text"
      },
      "source": [
        "### Contrast\n",
        "\n",
        "Constrast in a naive sense is difference is between the minimum and maximum intensity values.\n",
        "\n",
        "When the spread of intensities is large, high contrast and when the spread is less the image has a low contrast.\n",
        "\n",
        "### Constrast Stretching\n",
        "\n",
        "Low constrast images are in general useless. The features are seen better in high contrast and hence the imageis put through contrast stretching where the range of intensities is increased.\n",
        "\n",
        "For every pixel $a$,\n",
        "\\begin{equation}\n",
        "f(a) = a_{min} + (a - a_{low}) \\frac{a_{max} - a_{min}}{a_{high} - a_{low}}\n",
        "\\end{equation}\n",
        "\n",
        "The range is expanded from $[a_{low}, a_{high}]$ to $[a_{min}, a_{max}]$\n",
        "\n",
        "I am not sure why the division by 255 is done everywhere, why can't we do the math with [0, 255]? \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKZnXSSWOY1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Excercise: Do contrast stretching"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dQ1FFkKOgBr",
        "colab_type": "text"
      },
      "source": [
        "### Thresholding\n",
        "\n",
        "- Used to genearte a mask: *Object Segmentation*.\n",
        "- Used to perform morphological operations as well.\n",
        "\n",
        "Global to point tranformation as we look at the entire image and decide threshold!\n",
        "\n",
        "Binarization is done most of the times , where for every pixel $a$,\n",
        "\n",
        "$$\n",
        "f_{threshold}(a) = \\left\\{\n",
        "        \\begin{array}{ll}\n",
        "            a_0 & \\quad x < a_{threshold} \\\\\n",
        "            a_1 & \\quad x \\geq a_{threshold}\n",
        "        \\end{array}\n",
        "    \\right.\n",
        "$$\n",
        "\n",
        "In binarization $a_0 = 0$, and $a_1 = 1$.\n",
        "\n",
        "Histograms are helpful in choosing the threshold value. In case there is no significant drop in the histogram, we must prefer a different form of thresholding.\n",
        "\n",
        "### Adaptive Thresholding\n",
        "\n",
        "Neighborhood to point tranformation as we look at a window in the image and decide threshold for a point in the final image.\n",
        "\n",
        "Need not always work, is an area of research."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PPkmIhHPbiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Excercise: Simple thresholding\n",
        "# Read: Adaptive thresholding maths behind it "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS4PFQiQkN3W",
        "colab_type": "text"
      },
      "source": [
        "### Filtering\n",
        "\n",
        "Neighbourhood to point transformation.\n",
        "\n",
        "Modifying an enhancing an image, remove feature or highlight them.\n",
        "$$\n",
        "  g(x, y) = T \\cdot f(x, y)\n",
        "$$\n",
        "\n",
        "$T$ operates on a window of pixels.\n",
        "\n",
        "### Convolution\n",
        "\n",
        "Neighborhood to point operation where the output pixels is the weighted sum of the neighbourhood pixels.\n",
        "\n",
        "Mask filter $H$ values multiplied with the image pixel values that it is covering and then summed. \n",
        "\n",
        "$$\n",
        "I'(u, v) = \\sum_{(i,j)\\epsilon R_\\mu} I(u + i)\n",
        " \\cdot H(i, j)$$\n",
        "\n",
        "$R_\\mu$ is the set of all pixels covered by the filter.\n",
        "\n",
        "To do convolution over the edge pixels, we must pad the image with appropriate thickness of 0 zero filled rows around the image.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkatcYk6tXTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Excercise: Write a generic convolution function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhENBKNft07s",
        "colab_type": "text"
      },
      "source": [
        "### Smoothing / Low Pass Values\n",
        "\n",
        "Reducing noise and eliminating small details. \n",
        "\n",
        "Example,\n",
        "\n",
        "$$\n",
        "H = \\frac{1}{9}\n",
        "\\begin{bmatrix}\n",
        "1 & 1 & 1 \\\\\n",
        "1 & 1 & 1 \\\\\n",
        "1 & 1 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "### Sharpening / High Pass Values\n",
        "\n",
        "Highlight fine details and enhance blurry images.\n",
        "\n",
        "Generally 3 x 3 as larger means more effect of neighbouring pixels.\n",
        "\n",
        "Increases the brightness of center.\n",
        "\n",
        "Example,\n",
        "\n",
        "$$\n",
        "H = \n",
        "\\begin{bmatrix}\n",
        "0 & -1 & 0  \\\\\n",
        "-1 & 5 & -1 \\\\\n",
        "0 & -1 & 0\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Corners 0 means adjacents are only considered. \n",
        "\n",
        "Example,\n",
        "\n",
        "$$\n",
        "H = \n",
        "\\begin{bmatrix}\n",
        "-1 & -1 & -1  \\\\\n",
        "-1 & 5 & -1 \\\\\n",
        "-1 & -1 & -1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Now, here diagonal is also considered.\n",
        "\n",
        "The desired image after filtering is the original plus an appropriately scales high pass image.\n",
        "\n",
        "$$\n",
        "f_s = f + \\lambda f_h\n",
        "$$\n",
        "\n",
        "$\\lambda $ greater means center is sharpness increase.\n",
        "\n",
        "### Edge Enhancement\n",
        "\n",
        "#### Prewitt Opreator\n",
        "\n",
        "Horizontal and vertical edges are detected.\n",
        "\n",
        "$$\n",
        "H^P_x = \n",
        "\\begin{bmatrix}\n",
        "-1 \\; & 0 \\; & 1  \\\\\n",
        "-1 & 0 & 1 \\\\\n",
        "-1 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "H^P_y = \n",
        "\\begin{bmatrix}\n",
        "-1 & -1 & -1\\\\\n",
        "0 & 0 & 0\\\\\n",
        "1 & 1 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "#### Sobel Operator \n",
        "\n",
        "$$\n",
        "H^P_x = \n",
        "\\begin{bmatrix}\n",
        "-1 & 0 & 1  \\\\\n",
        "-2 & 0 & 2 \\\\\n",
        "-1 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "H^P_y = \n",
        "\\begin{bmatrix}\n",
        "-1 & -2 & -1\\\\\n",
        "0 & 0 & 0\\\\\n",
        "1 & 2 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "The edges obtained after using the the matrices on the image. The two results are then combined using magnitude. \n",
        "\n",
        "$$\n",
        "magnitude = \\sqrt{x^2 + y^2}\n",
        "$$\n",
        "\n",
        "Magnitude is added to the original image to emphasise the edges. Done in the same manner as linear shift.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7I6RG-VZ_qj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task: Calculate number of windows using edge enhancement"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}